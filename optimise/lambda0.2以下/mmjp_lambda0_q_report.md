# MMJP lambda0 sweep (q=0..51: lambda0=0.0..0.199)

このレポートは **MMJP (LM+supervised CRF)** の推論ハイパーパラメータ `lambda0` を、Q8.8(1/256刻み)で **0.0〜約0.2** まで全探索した結果です。
評価は bench3 と同じく、`raw_test_181.txt` と `labeled_test_181_nospacegold.txt` の **単語開始境界F1** です（181文、gold境界数=5462）。

## 最良点
- **best F1**: q=12 (lambda0=0.046875)  /  P=0.851328  R=0.827170  **F1=0.839075**
- 分割粒度: avg_tokens/sent=29.3204, avg_token_len=1.8184

## 近似最適（トークン数を減らす）
- F1が best-0.001 以内で最も粗い点: q=38 (lambda0=0.148438) / F1=0.838119, avg_tokens/sent=27.7403
- F1が best-0.002 以内で最も粗い点: q=50 (lambda0=0.195312) / F1=0.837809, avg_tokens/sent=26.8122

## 代表点（抜粋）
qとlambda0は `lambda0 = q/256`。tok20k_secは 20k文トークナイズの実測秒（/usr/bin/time -v）。

|         q |   lambda0 |       F1 |        P |        R |   avg_tokens/sent |   avg_tok_len |   tok20k_sec |   tok20k_rss_kb |
|----------:|----------:|---------:|---------:|---------:|------------------:|--------------:|-------------:|----------------:|
| 51.000000 |  0.199219 | 0.835862 | 0.891331 | 0.786891 |         26.640900 |      2.001200 |     0.410000 |     4024.000000 |
| 50.000000 |  0.195312 | 0.837809 | 0.890377 | 0.791102 |         26.812200 |      1.988500 |     0.410000 |     3308.000000 |
| 38.000000 |  0.148438 | 0.838119 | 0.874925 | 0.804284 |         27.740300 |      1.921900 |     0.420000 |     4252.000000 |
| 31.000000 |  0.121094 | 0.835779 | 0.865177 | 0.808312 |         28.193400 |      1.891000 |     0.480000 |     4692.000000 |
| 26.000000 |  0.101562 | 0.835279 | 0.859551 | 0.812340 |         28.519300 |      1.869400 |     0.470000 |     5068.000000 |
| 20.000000 |  0.078125 | 0.836387 | 0.854605 | 0.818931 |         28.917100 |      1.843700 |     0.410000 |     4160.000000 |
| 15.000000 |  0.058594 | 0.838175 | 0.852785 | 0.824057 |         29.160200 |      1.828300 |     0.460000 |     5160.000000 |
| 14.000000 |  0.054688 | 0.839063 | 0.851887 | 0.826620 |         29.281800 |      1.820800 |     0.410000 |     3748.000000 |
| 13.000000 |  0.050781 | 0.839015 | 0.851593 | 0.826803 |         29.298300 |      1.819700 |     0.410000 |     3680.000000 |
| 12.000000 |  0.046875 | 0.839075 | 0.851328 | 0.827170 |         29.320400 |      1.818400 |     0.440000 |     4248.000000 |
| 10.000000 |  0.039062 | 0.838632 | 0.849258 | 0.828268 |         29.430900 |      1.811500 |     0.440000 |     4420.000000 |
|  5.000000 |  0.019531 | 0.837938 | 0.848798 | 0.827353 |         29.414400 |      1.812500 |     0.400000 |     4984.000000 |
|  0.000000 |  0.000000 | 0.835600 | 0.844586 | 0.826803 |         29.541400 |      1.804800 |     0.410000 |     3736.000000 |

## Paretoフロンティア（F1最大化・トークン数最小化）
`avg_tokens/sent` を小さく（粗く）しつつ、F1を落とさない点の集合（非劣解）です。
件数: 7

|         q |   lambda0 |       F1 |   avg_tokens/sent |   avg_tok_len |
|----------:|----------:|---------:|------------------:|--------------:|
| 51.000000 |  0.199219 | 0.835862 |         26.640900 |      2.001200 |
| 50.000000 |  0.195312 | 0.837809 |         26.812200 |      1.988500 |
| 39.000000 |  0.152344 | 0.837995 |         27.696100 |      1.925000 |
| 38.000000 |  0.148438 | 0.838119 |         27.740300 |      1.921900 |
| 15.000000 |  0.058594 | 0.838175 |         29.160200 |      1.828300 |
| 14.000000 |  0.054688 | 0.839063 |         29.281800 |      1.820800 |
| 12.000000 |  0.046875 | 0.839075 |         29.320400 |      1.818400 |

## READMEに追記する“最適レシピ”案

```bash
# 例: まずはモデル学習（lambda0は推論時係数なので1.0でOK）
mmjp_train \
  --corpus unlabeled_train_20k.txt \
  --out model.bin \
  --vocab 8000 --max_piece_len 8 --iters 5 \
  --mdl_lambda_len 0.15 \
  --crf_supervised labeled_train_800.txt \
  --crf_opt lbfgs --crf_epochs 30 --crf_l2 1e-4

# 推論時: lambda0を best (q=12 -> 0.046875) にする
# ※現状tokenize側に --lambda0 上書きが無いので、ヘッダ(オフセット32のint16)をパッチする
python patch_lambda0_q.py model.bin model_lam_q012.bin 12
mmjp_tokenize --model model_lam_q012.bin < input.txt > pred.txt
```
